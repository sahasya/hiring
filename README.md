**Linear Regression**
Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. ... A linear regression line has an equation of the form **Y = a + bX**, where 'X' is the explanatory variable,'Y' is the dependent variable ,'b' is slope and 'a' is the intercept.

**Multiple Linear Regression**
Multiple regression is an extension of simple linear regression. It is used when we want to predict the value of a variable based on the value of two or more other variables. The variable we want to predict is called the dependent variable (or sometimes, the outcome, target or criterion variable).
A multiple linear regression model with k predictor variables X1, X2, ..., Xk
and a response Y , can be written as
**y = β0 + β1x1 + β2x2 + ··· βkxk + c**
As before, the 'c' are the residual terms of the model and the distribution assumption we place on the residuals will allow us later to do inference on the remaining model parameters. Interpret the meaning of the regression coefficients
β0, β1, β2, ..., βk in this model.

**Uses**
If the goal is prediction, forecasting, or error reduction,linear regression can be used to fit a predictive model to an observed data set of values of the response and explanatory variables.
If the goal is to explain variation in the response variable that can be attributed to variation in the explanatory variables, linear regression analysis can be applied to quantify the strength of the relationship between the response and the explanatory variables, and in particular to determine whether some explanatory variables may have no linear relationship with the response at all, or to identify which subsets of explanatory variables may contain redundant information about the response.

